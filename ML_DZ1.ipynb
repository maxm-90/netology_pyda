{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.datasets.samples_generator import make_classification\n",
    "import pylab\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_classification(n_samples=100, n_features=2,n_informative=1, n_redundant=1,\n",
    "                           random_state=2, n_classes=2, n_clusters_per_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, n =np.shape(x)\n",
    "m, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.c_[np.ones(m), x]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_2(alpha, x, y, numIterations):\n",
    "    \"\"\"\n",
    "    Функция реализует алгоритм градиентного спуска для задачи классификации.\n",
    "    Логистическая регрессия.\n",
    "    \"\"\"\n",
    "    \n",
    "    m = x.shape[0] # 100\n",
    "    theta = np.ones(3) # [ 1.  1.  1.]\n",
    "    \n",
    "    for iter in range( 0, numIterations ):\n",
    "        P = 1/(1 + np.exp(-np.dot(x, theta))) # вектор вероятностей принадлежности к классу 1\n",
    "        \n",
    "        J = np.sum(-y*np.log(P)-(1-y)*np.log(1-P))/m  # функция потерь\n",
    "        \n",
    "        print( \"iter %s | J: %.3f\" % (iter, J) )\n",
    "        \n",
    "        gradient = np.dot((P-y),x)        \n",
    "        theta = theta - alpha * gradient  # update\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 | J: 0.391\n",
      "iter 1 | J: 0.211\n",
      "iter 2 | J: 0.204\n",
      "iter 3 | J: 0.200\n",
      "iter 4 | J: 0.197\n",
      "iter 5 | J: 0.196\n",
      "iter 6 | J: 0.194\n",
      "iter 7 | J: 0.193\n",
      "iter 8 | J: 0.192\n",
      "iter 9 | J: 0.192\n",
      "iter 10 | J: 0.191\n",
      "iter 11 | J: 0.191\n",
      "iter 12 | J: 0.191\n",
      "iter 13 | J: 0.190\n",
      "iter 14 | J: 0.190\n",
      "iter 15 | J: 0.190\n",
      "iter 16 | J: 0.190\n",
      "iter 17 | J: 0.190\n",
      "iter 18 | J: 0.189\n",
      "iter 19 | J: 0.189\n",
      "iter 20 | J: 0.189\n",
      "iter 21 | J: 0.189\n",
      "iter 22 | J: 0.189\n",
      "iter 23 | J: 0.189\n",
      "iter 24 | J: 0.189\n",
      "iter 25 | J: 0.189\n",
      "iter 26 | J: 0.189\n",
      "iter 27 | J: 0.189\n",
      "iter 28 | J: 0.189\n",
      "iter 29 | J: 0.189\n",
      "iter 30 | J: 0.189\n",
      "iter 31 | J: 0.189\n",
      "iter 32 | J: 0.189\n",
      "iter 33 | J: 0.189\n",
      "iter 34 | J: 0.189\n",
      "iter 35 | J: 0.189\n",
      "iter 36 | J: 0.189\n",
      "iter 37 | J: 0.189\n",
      "iter 38 | J: 0.189\n",
      "iter 39 | J: 0.189\n",
      "iter 40 | J: 0.189\n",
      "iter 41 | J: 0.189\n",
      "iter 42 | J: 0.189\n",
      "iter 43 | J: 0.189\n",
      "iter 44 | J: 0.189\n",
      "iter 45 | J: 0.189\n",
      "iter 46 | J: 0.189\n",
      "iter 47 | J: 0.189\n",
      "iter 48 | J: 0.189\n",
      "iter 49 | J: 0.189\n",
      "iter 50 | J: 0.189\n",
      "iter 51 | J: 0.189\n",
      "iter 52 | J: 0.189\n",
      "iter 53 | J: 0.189\n",
      "iter 54 | J: 0.189\n",
      "iter 55 | J: 0.189\n",
      "iter 56 | J: 0.189\n",
      "iter 57 | J: 0.189\n",
      "iter 58 | J: 0.189\n",
      "iter 59 | J: 0.189\n",
      "iter 60 | J: 0.189\n",
      "iter 61 | J: 0.189\n",
      "iter 62 | J: 0.189\n",
      "iter 63 | J: 0.189\n",
      "iter 64 | J: 0.189\n",
      "iter 65 | J: 0.189\n",
      "iter 66 | J: 0.189\n",
      "iter 67 | J: 0.189\n",
      "iter 68 | J: 0.189\n",
      "iter 69 | J: 0.189\n",
      "iter 70 | J: 0.189\n",
      "iter 71 | J: 0.189\n",
      "iter 72 | J: 0.189\n",
      "iter 73 | J: 0.189\n",
      "iter 74 | J: 0.189\n",
      "iter 75 | J: 0.189\n",
      "iter 76 | J: 0.189\n",
      "iter 77 | J: 0.189\n",
      "iter 78 | J: 0.189\n",
      "iter 79 | J: 0.189\n",
      "iter 80 | J: 0.189\n",
      "iter 81 | J: 0.189\n",
      "iter 82 | J: 0.189\n",
      "iter 83 | J: 0.189\n",
      "iter 84 | J: 0.189\n",
      "iter 85 | J: 0.189\n",
      "iter 86 | J: 0.189\n",
      "iter 87 | J: 0.189\n",
      "iter 88 | J: 0.189\n",
      "iter 89 | J: 0.189\n",
      "iter 90 | J: 0.189\n",
      "iter 91 | J: 0.189\n",
      "iter 92 | J: 0.189\n",
      "iter 93 | J: 0.189\n",
      "iter 94 | J: 0.189\n",
      "iter 95 | J: 0.189\n",
      "iter 96 | J: 0.189\n",
      "iter 97 | J: 0.189\n",
      "iter 98 | J: 0.189\n",
      "iter 99 | J: 0.189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.95931362, 3.32890998, 1.57553507])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent_2 (0.05, x, y, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Линейный классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = make_classification(n_samples=100, n_features=2,n_informative=1, n_redundant=1,\n",
    "                           random_state=133, n_classes=2, n_clusters_per_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.c_[np.ones(m), x1]\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1[y1==0] = -1 # переводим с нуля на -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_1(alpha, x1, y1, numIterations):\n",
    "    \"\"\"\n",
    "    Функция реализует алгоритм градиентного спуска для задачи классификации.\n",
    "    Линейный классификатор.\n",
    "    \"\"\"\n",
    "    \n",
    "    m = x1.shape[0] # 100\n",
    "    theta = np.ones(3) # [ 1.  1.  1.]\n",
    "    \n",
    "    for iter in range( 0, numIterations ):\n",
    "        hypothesis = np.dot(x1, theta) # тут вычисляется значение как в регресии\n",
    "        hypothesis[hypothesis < 0] = -1 # Здесь смотрим на знак, если меньше нуля, то -1\n",
    "        hypothesis[hypothesis >= 0] = 1 # если больше нуля, то 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        J1 = 0.5 * np.sum(((np.dot(x1, theta))-y1)**2)  # функция потерь\n",
    "        # Данную функцию я взял из статьи, которую ты мне скидывал.\n",
    "        #Ошибка - это расстояние от значения метки класса до гиперплоскости активации\n",
    "        # Как в линнейном классификаторе мы можем использовать такую же функцию ошибки как в логистической регрессии?\n",
    "        # Как я понимаю, в лог регрессии все завязано на вероятности. А в линейном на отступе\n",
    "        \n",
    "        print( \"iter %s | J: %.3f\" % (iter, J1) )\n",
    "        gradient = np.dot(((np.dot(x1, theta))-y1), x1)\n",
    "        theta = theta - alpha * gradient  # update\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 | J: 72.373\n",
      "iter 1 | J: 13.286\n",
      "iter 2 | J: 11.847\n",
      "iter 3 | J: 11.695\n",
      "iter 4 | J: 11.679\n",
      "iter 5 | J: 11.677\n",
      "iter 6 | J: 11.677\n",
      "iter 7 | J: 11.677\n",
      "iter 8 | J: 11.677\n",
      "iter 9 | J: 11.677\n",
      "iter 10 | J: 11.677\n",
      "iter 11 | J: 11.677\n",
      "iter 12 | J: 11.677\n",
      "iter 13 | J: 11.677\n",
      "iter 14 | J: 11.677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.01621213,  0.96486825,  0.66581246])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent_1(0.01, x1, y1, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
